{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8cc9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Value Function:\n",
      "[[65.607346 72.89734  80.997345 89.997345]\n",
      " [59.046345  0.       89.997345 99.997345]\n",
      " [65.607346 72.89734  80.997345 89.997345]\n",
      " [59.046345 65.607346 72.89734  80.997345]]\n",
      "\n",
      "Optimal Policy:\n",
      "[['R' 'R' 'D' 'D']\n",
      " ['U' 'W' 'R' 'R']\n",
      " ['R' 'R' 'U' 'U']\n",
      " ['U' 'U' 'U' 'U']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/_4_3bkv156zfzhgs_qdg_3rw0000gp/T/ipykernel_53368/626287522.py:44: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  optimal_policy = np.zeros_like(grid_world, dtype=np.str)\n"
     ]
    }
   ],
   "source": [
    "# Bellmann equation implementation for Gridworld problem\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the grid-world environment\n",
    "grid_world = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, -1, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Define the rewards for each cell\n",
    "rewards = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 10],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Define the discount factor\n",
    "discount_factor = 0.9\n",
    "\n",
    "# Define the number of iterations for the Bellman equation\n",
    "num_iterations = 100\n",
    "\n",
    "# Initialize the value function array\n",
    "value_function = np.zeros_like(grid_world, dtype=np.float32)\n",
    "\n",
    "# Perform value iteration\n",
    "for _ in range(num_iterations):\n",
    "    updated_value_function = np.copy(value_function)\n",
    "    for i in range(grid_world.shape[0]):\n",
    "        for j in range(grid_world.shape[1]):\n",
    "            if grid_world[i, j] == -1:  # Skip walls or obstacles\n",
    "                continue\n",
    "            up_value = value_function[max(i - 1, 0), j]\n",
    "            down_value = value_function[min(i + 1, grid_world.shape[0] - 1), j]\n",
    "            left_value = value_function[i, max(j - 1, 0)]\n",
    "            right_value = value_function[i, min(j + 1, grid_world.shape[1] - 1)]\n",
    "            max_value = max(up_value, down_value, left_value, right_value)\n",
    "            updated_value_function[i, j] = rewards[i, j] + discount_factor * max_value\n",
    "    value_function = updated_value_function\n",
    "\n",
    "# Find the optimal policy\n",
    "optimal_policy = np.zeros_like(grid_world, dtype=np.str)\n",
    "for i in range(grid_world.shape[0]):\n",
    "    for j in range(grid_world.shape[1]):\n",
    "        if grid_world[i, j] == -1:\n",
    "            optimal_policy[i, j] = \"W\"  # Mark walls or obstacles\n",
    "        else:\n",
    "            up_value = value_function[max(i - 1, 0), j]\n",
    "            down_value = value_function[min(i + 1, grid_world.shape[0] - 1), j]\n",
    "            left_value = value_function[i, max(j - 1, 0)]\n",
    "            right_value = value_function[i, min(j + 1, grid_world.shape[1] - 1)]\n",
    "            max_value = max(up_value, down_value, left_value, right_value)\n",
    "            if max_value == up_value:\n",
    "                optimal_policy[i, j] = \"U\"\n",
    "            elif max_value == down_value:\n",
    "                optimal_policy[i, j] = \"D\"\n",
    "            elif max_value == left_value:\n",
    "                optimal_policy[i, j] = \"L\"\n",
    "            elif max_value == right_value:\n",
    "                optimal_policy[i, j] = \"R\"\n",
    "\n",
    "# Print the results\n",
    "print(\"Optimal Value Function:\")\n",
    "print(value_function)\n",
    "print(\"\\nOptimal Policy:\")\n",
    "print(optimal_policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec985225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'swimming', 'swimming', 'running', 'running', 'running', 'running', 'running', 'running', 'running', 'running', 'running']\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a Python code based on Bellman equation (include value function) as follows: \n",
    "#an agent can performs two types of actions endurnace (weight lifting) and performance (running, swimming). \n",
    "#The agent get a user data with energy and interested (endurance and performance), \n",
    "#then it distributes the actions based on the given energy. \n",
    "#For example a user with 10 units of energy, and performance interest will be 7 units performance and 3 units endurance. \n",
    "# the output should be a list of actions for the given number of energy. For example, energy=3, interested=performance. The output will be 1: weight lifting, 2: swimming, 3: running.\n",
    "\n",
    "import random\n",
    "\n",
    "def bellman_equation(energy, interested):\n",
    "  \"\"\"\n",
    "  Performs Bellman equation to distribute actions based on given energy and interested.\n",
    "\n",
    "  Args:\n",
    "    energy: The amount of energy the user has.\n",
    "    interested: The user's interest in endurance and performance.\n",
    "\n",
    "  Returns:\n",
    "    A list of actions for the given number of energy.\n",
    "  \"\"\"\n",
    "\n",
    "  actions = []\n",
    "  if interested == \"endurance\":\n",
    "    actions = [\"weight lifting\"]\n",
    "  elif interested == \"performance\":\n",
    "    actions = [\"running\", \"swimming\"]\n",
    "  else:\n",
    "    raise ValueError(\"Invalid interested value\")\n",
    "\n",
    "  # Randomly distribute the actions based on the user's energy.\n",
    "\n",
    "  for i in range(energy):\n",
    "    actions.append(random.choice(actions))\n",
    "\n",
    "  return actions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  energy = 10\n",
    "  interested = \"performance\"\n",
    "  actions = bellman_equation(energy, interested)\n",
    "  print(actions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342c41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
