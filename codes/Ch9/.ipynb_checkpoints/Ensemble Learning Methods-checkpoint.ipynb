{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------ Stacking example ----------\n",
    "#--- Source : Scikit learn package ------\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "X, y = load_iris(return_X_y=True)\n",
    "estimators = [\n",
    "     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "     ('svr', make_pipeline(StandardScaler(), LinearSVC(random_state=42)))\n",
    " ]\n",
    "clf = StackingClassifier(\n",
    "     estimators=estimators, final_estimator=LogisticRegression()\n",
    " )\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, stratify=y, random_state=42\n",
    " )\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.866 (0.029)\n",
      ">knn 0.931 (0.025)\n",
      ">cart 0.824 (0.047)\n",
      ">svm 0.957 (0.020)\n",
      ">bayes 0.833 (0.031)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------- Another Stacking example -----------\n",
    "# Source: https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python\n",
    "# compare standalone models for binary classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "\treturn X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['lr'] = LogisticRegression()\n",
    "\tmodels['knn'] = KNeighborsClassifier()\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['svm'] = SVC()\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#------ Random Forest example ----------\n",
    "#--- Source : Scikitlearn package ------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification \n",
    "\n",
    "# make_classification Generate a random n-class classification problem.\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                            n_informative=2, n_redundant=0,\n",
    "                            random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X, y)\n",
    "print(clf.predict([[0, 0, 0, 0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.806 (0.041)\n"
     ]
    }
   ],
   "source": [
    "#----- Adaboost algorithm for classification ----\n",
    "# Source: https://machinelearningmastery.com/adaboost-ensemble-in-python/?__s=ef7ilh4zzwoas113fe2l \n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "# define the model\n",
    "model = AdaBoostClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.917\n",
      "The mean squared error (MSE) on test set: 5.1729\n"
     ]
    }
   ],
   "source": [
    "#------------- GBDT example --------------\n",
    "# source: https://vitalflux.com/gradient-boosting-regression-python-examples/\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#\n",
    "# Load the Boston Dataset\n",
    "#\n",
    "bhp = datasets.load_boston()\n",
    "#\n",
    "# Create Training and Test Split\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(bhp.data, bhp.target, random_state=42, test_size=0.1)\n",
    "#\n",
    "# Standardize the dataset\n",
    "#\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "#\n",
    "# Hyperparameters for GradientBoostingRegressor\n",
    "#\n",
    "gbr_params = {'n_estimators': 1000,\n",
    "          'max_depth': 3,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "#\n",
    "# Create an instance of gradient boosting regressor\n",
    "#\n",
    "gbr = GradientBoostingRegressor(**gbr_params)\n",
    "#\n",
    "# Fit the model\n",
    "#\n",
    "gbr.fit(X_train_std, y_train)\n",
    "#\n",
    "# Print Coefficient of determination R^2\n",
    "#\n",
    "print(\"Model Accuracy: %.3f\" % gbr.score(X_test_std, y_test))\n",
    "#\n",
    "# Create the mean squared error\n",
    "#\n",
    "mse = mean_squared_error(y_test, gbr.predict(X_test_std))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.0-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 616 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.22.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.5.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# ------ XGBoost Example ----------\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "\n",
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.2-py3-none-macosx_10_14_x86_64.macosx_10_15_x86_64.macosx_11_0_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (1.22.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: wheel in /opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (0.35.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l2: 0.217427\tvalid_0's l1: 0.450862\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l2: 0.20365\tvalid_0's l1: 0.435501\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's l2: 0.191447\tvalid_0's l1: 0.42114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's l2: 0.180522\tvalid_0's l1: 0.407375\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's l2: 0.170539\tvalid_0's l1: 0.394098\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's l2: 0.159102\tvalid_0's l1: 0.379485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's l2: 0.149889\tvalid_0's l1: 0.366513\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's l2: 0.141875\tvalid_0's l1: 0.354802\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's l2: 0.134391\tvalid_0's l1: 0.343267\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's l2: 0.12655\tvalid_0's l1: 0.331225\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's l2: 0.121017\tvalid_0's l1: 0.321092\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's l2: 0.116545\tvalid_0's l1: 0.311883\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's l2: 0.112594\tvalid_0's l1: 0.303131\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's l2: 0.107068\tvalid_0's l1: 0.292931\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's l2: 0.1021\tvalid_0's l1: 0.283252\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's l2: 0.0979896\tvalid_0's l1: 0.274844\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's l2: 0.0945496\tvalid_0's l1: 0.267198\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's l2: 0.0904485\tvalid_0's l1: 0.258906\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's l2: 0.0879433\tvalid_0's l1: 0.252165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's l2: 0.0846574\tvalid_0's l1: 0.244773\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.0846574\tvalid_0's l1: 0.244773\n",
      "The RMSE of prediction is: 0.2909594108724933\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# training the model\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=5)])\n",
    "\n",
    "# save model to file\n",
    "#gbm.save_model('model.txt')\n",
    "\n",
    "# prediction\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# evaluation\n",
    "rmse_test = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "print(f'The RMSE of prediction is: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.0.4-cp38-none-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (12.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.7 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: plotly in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (5.3.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.3.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.22.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.15.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 8.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (3.3.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from plotly->catboost) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2020.6.20)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (8.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.0.4 graphviz-0.20\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6.1237244\ttotal: 56.1ms\tremaining: 56.1ms\n",
      "1:\tlearn: 4.5927933\ttotal: 56.8ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Source: https://catboost.ai/en/docs/concepts/python-usages-examples\n",
    "from catboost import CatBoostRegressor\n",
    "# Initialize data\n",
    "\n",
    "train_data = [[1, 4, 5, 6],\n",
    "              [4, 5, 6, 7],\n",
    "              [30, 40, 50, 60]]\n",
    "\n",
    "eval_data = [[2, 4, 6, 8],\n",
    "             [1, 4, 50, 60]]\n",
    "\n",
    "train_labels = [10, 20, 30]\n",
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=2,\n",
    "                          learning_rate=1,\n",
    "                          depth=2)\n",
    "# Fit model\n",
    "model.fit(train_data, train_labels)\n",
    "# Get predictions\n",
    "preds = model.predict(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
