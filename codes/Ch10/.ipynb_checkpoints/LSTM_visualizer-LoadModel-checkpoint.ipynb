{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --upgrade keras\n",
    "# run this command in terminal: ! conda install cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BEHD9-KMjeUl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "\n",
    "# Imports for visualisations\n",
    "from IPython.display import HTML as html_print\n",
    "from IPython.display import display\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tii_RTx6mN8K",
    "outputId": "67ef0b1c-4062-41e7-9474-4e53b17d5c8d"
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "filename = \"ggmarques.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = re.sub(r'[ ]+', ' ', raw_text)\n",
    "\n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6mJXkZbsYqF",
    "outputId": "d58e29ac-741c-4fae-d9ea-3ae6b76b4b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  832410\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n",
    "\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "# define the checkpoint, early stopping can be definied here as well:\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "# then instead of [callbacks_list] we can use [es]\n",
    "#check this link https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jzY5DQUzrDF",
    "outputId": "e8959275-9ca6-4966-9ea4-6f45190bf49a"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# load model from the Repository\n",
    "json_file = open('LSTM1-marqoues-300epoch.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"LSTM1-marqoues-300epoch-weights.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# build the LSTM model\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "loaded_model.summary()\n",
    "\n",
    "#Train the built model for the next 200 epochs, On Amazon P3, with one GPU I have reduced batch_size from 2048 to 1024\n",
    "loaded_model.fit(X, y, epochs=300, batch_size=1024, callbacks=callbacks_list ) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxb-gWFwBsp4",
    "outputId": "f5ea6f50-f504-479a-e6f4-5ac14fa3304b"
   },
   "outputs": [],
   "source": [
    "#---- Since it takes a long time, we could save the model and next time read the saved model\n",
    "# serialize model to JSON\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"LSTM1-marqoues-500epoch.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"LSTM1-marqoues-500epoch-weights.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43lXqEmqz1sY",
    "outputId": "fd39d06d-b059-4108-848c-1dd972015b92"
   },
   "outputs": [],
   "source": [
    "\n",
    "#--------- Now the model is ready and we start to focus on Visualization -----------\n",
    "\n",
    "# Get output from intermediate layer to visualize activations\n",
    "\n",
    "# 3rd layer is LSTM layer with output shape (Batch_Size, 512)\n",
    "lstm = model.layers[2]\n",
    "print (lstm.output)\n",
    "\n",
    "attn_func = K.function(inputs = [model.inputs[0]],  \n",
    "                       outputs = [lstm.output])\n",
    "\n",
    "# get html element\n",
    "def cstr(s, color='black'):\n",
    "    if s == ' ':\n",
    "        return \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
    "    else:\n",
    "        return \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
    "\n",
    "# print html\n",
    "def print_color(t):\n",
    "    display(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
    "\n",
    "# get appropriate color for value\n",
    "def get_clr(value):\n",
    "    colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
    "        '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
    "        '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
    "        '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
    "    value = int((value * 100) / 5)\n",
    "    return colors[value]\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    z = 1/(1 + np.exp(-x)) \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcJItI7iz1wb"
   },
   "outputs": [],
   "source": [
    "def visualize(output_values, result_list, cell_no):\n",
    "    print(\"\\nCell Number:\", cell_no, \"\\n\")\n",
    "    text_colours = []\n",
    "    for i in range(len(output_values)):\n",
    "        text = (result_list[i], get_clr(output_values[i][cell_no]))\n",
    "        text_colours.append(text)\n",
    "    print_color(text_colours)\n",
    "    \n",
    "# Get Predictions from random sequence\n",
    "def get_predictions(data):\n",
    "    start = np.random.randint(0, len(data)-1)\n",
    "    pattern = data[start]\n",
    "    result_list, output_values = [], []\n",
    "    print(\"Seed:\")\n",
    "    print(\"\\\"\" + ''.join([int_to_char[value] for value in pattern]) + \"\\\"\")\n",
    "    print(\"\\nGenerated:\")\n",
    "\n",
    "    for i in range(1000):\n",
    "        # Reshaping input array for predicting next character\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = x / float(n_vocab)\n",
    "\n",
    "        # Prediction\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "\n",
    "        # LSTM Activations\n",
    "        output = attn_func([x])[0][0]\n",
    "        output = sigmoid(output)\n",
    "        output_values.append(output)\n",
    "\n",
    "        # Predicted Character\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_char[index]\n",
    "\n",
    "        # Preparing input for next character\n",
    "        seq_in = [int_to_char[value] for value in pattern]\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "        # Saving generated characters\n",
    "        result_list.append(result)\n",
    "    return output_values, result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "disNTl8jepTq",
    "outputId": "d44c4bec-5067-4693-ec64-e58874b2dced"
   },
   "outputs": [],
   "source": [
    "output_values, result_list = get_predictions(dataX)\n",
    "\n",
    "for cell_no in [500, 435, 463, 470, 475, 480, 350, 400]:\n",
    "    visualize(output_values, result_list, cell_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM visualizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
